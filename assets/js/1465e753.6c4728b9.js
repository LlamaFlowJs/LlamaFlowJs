"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2099],{6696:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>p,frontMatter:()=>l,metadata:()=>s,toc:()=>c});var t=i(65723),a=i(43327);const l={},r="Observability",s={id:"observability/index",title:"Observability",description:"llamaflowjs provides one-click observability \ud83d\udd2d to allow you to build principled LLM applications in a production setting.",source:"@site/docs/observability/index.md",sourceDirName:"observability",slug:"/observability/",permalink:"/observability/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"mySidebar",previous:{title:"LlamaCloud",permalink:"/modules/llamacloud"},next:{title:"llamaflowjs",permalink:"/api/"}},o={},c=[{value:"OpenLLMetry",id:"openllmetry",level:2},{value:"Usage Pattern",id:"usage-pattern",level:3},{value:"Langtrace",id:"langtrace",level:2},{value:"Install",id:"install",level:4},{value:"Initialize",id:"initialize",level:4}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"observability",children:"Observability"}),"\n",(0,t.jsxs)(n.p,{children:["llamaflowjs provides ",(0,t.jsx)(n.strong,{children:"one-click observability"})," \ud83d\udd2d to allow you to build principled LLM applications in a production setting."]}),"\n",(0,t.jsx)(n.p,{children:"A key requirement for principled development of LLM applications over your data (RAG systems, agents) is being able to observe, debug, and evaluate\nyour system - both as a whole and for each component."}),"\n",(0,t.jsx)(n.p,{children:"This feature allows you to seamlessly integrate the llamaflowjs library with powerful observability/evaluation tools offered by our partners.\nConfigure a variable once, and you'll be able to do things like the following:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"View LLM/prompt inputs/outputs"}),"\n",(0,t.jsx)(n.li,{children:"Ensure that the outputs of any component (LLMs, embeddings) are performing as expected"}),"\n",(0,t.jsx)(n.li,{children:"View call traces for both indexing and querying"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Each provider has similarities and differences. Take a look below for the full set of guides for each one!"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#openllmetry",children:"OpenLLMetry"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#langtrace",children:"Langtrace"})}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"openllmetry",children:"OpenLLMetry"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/traceloop/openllmetry-js",children:"OpenLLMetry"})," is an open-source project based on OpenTelemetry for tracing and monitoring\nLLM applications. It connects to ",(0,t.jsx)(n.a,{href:"https://www.traceloop.com/docs/openllmetry/integrations/introduction",children:"all major observability platforms"})," and installs in minutes."]}),"\n",(0,t.jsx)(n.h3,{id:"usage-pattern",children:"Usage Pattern"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"npm install @traceloop/node-server-sdk\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:'import * as traceloop from "@traceloop/node-server-sdk";\n\ntraceloop.initialize({\n  apiKey: process.env.TRACELOOP_API_KEY,\n  disableBatch: true,\n});\n'})}),"\n",(0,t.jsx)(n.h2,{id:"langtrace",children:"Langtrace"}),"\n",(0,t.jsx)(n.p,{children:"Enhance your observability with Langtrace, a robust open-source tool supports OpenTelemetry and is designed to trace, evaluate, and manage LLM applications seamlessly. Langtrace integrates directly with llamaflowjs, offering detailed, real-time insights into performance metrics such as accuracy, evaluations, and latency."}),"\n",(0,t.jsx)(n.h4,{id:"install",children:"Install"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Self-host or sign-up and generate an API key using ",(0,t.jsx)(n.a,{href:"https://www.langtrace.ai",children:"Langtrace"})," Cloud"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"npm install @langtrase/typescript-sdk\n"})}),"\n",(0,t.jsx)(n.h4,{id:"initialize",children:"Initialize"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-js",children:'import * as Langtrace from "@langtrase/typescript-sdk";\nLangtrace.init({ api_key: "<YOUR_API_KEY>" });\n'})}),"\n",(0,t.jsx)(n.p,{children:"Features:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"OpenTelemetry compliant, ensuring broad compatibility with observability platforms."}),"\n",(0,t.jsx)(n.li,{children:"Provides comprehensive logs and detailed traces of all components."}),"\n",(0,t.jsx)(n.li,{children:"Real-time monitoring of accuracy, evaluations, usage, costs, and latency."}),"\n",(0,t.jsxs)(n.li,{children:["For more configuration options and details, visit ",(0,t.jsx)(n.a,{href:"https://docs.langtrace.ai/introduction",children:"Langtrace Docs"}),"."]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},43327:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>s});var t=i(22155);const a={},l=t.createContext(a);function r(e){const n=t.useContext(l);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),t.createElement(l.Provider,{value:n},e.children)}}}]);