"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1716],{38834:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var a=t(65723),r=t(43327);const i={},o="Adding Retrieval-Augmented Generation (RAG)",s={id:"guides/agents/agentic_rag",title:"Adding Retrieval-Augmented Generation (RAG)",description:"While an agent that can perform math is nifty (LLMs are usually not very good at math), LLM-based applications are always more interesting when they work with large amounts of data. In this case, we're going to use a 200-page PDF of the proposed budget of the city of San Francisco for fiscal years 2024-2024 and 2024-2025. It's a great example because it's extremely wordy and full of tables of figures, which present a challenge for humans and LLMs alike.",source:"@site/docs/guides/agents/4_agentic_rag.mdx",sourceDirName:"guides/agents",slug:"/guides/agents/agentic_rag",permalink:"/LlamaFlowJs/guides/agents/agentic_rag",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:4,frontMatter:{},sidebar:"mySidebar",previous:{title:"Using a local model via Ollama",permalink:"/LlamaFlowJs/guides/agents/local_model"},next:{title:"A RAG agent that does math",permalink:"/LlamaFlowJs/guides/agents/rag_and_tools"}},d={},l=[{value:"New dependencies",id:"new-dependencies",level:3},{value:"Add an embedding model",id:"add-an-embedding-model",level:3},{value:"Load data using SimpleDirectoryReader",id:"load-data-using-simpledirectoryreader",level:3},{value:"Index our data",id:"index-our-data",level:3},{value:"Configure a retriever",id:"configure-a-retriever",level:3},{value:"Configure how many documents to retrieve",id:"configure-how-many-documents-to-retrieve",level:3},{value:"Create a query engine",id:"create-a-query-engine",level:3},{value:"Define the query engine as a tool",id:"define-the-query-engine-as-a-tool",level:3},{value:"Create the agent as before",id:"create-the-agent-as-before",level:3}];function c(e){const n={a:"a",code:"code",em:"em",h1:"h1",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"adding-retrieval-augmented-generation-rag",children:"Adding Retrieval-Augmented Generation (RAG)"}),"\n",(0,a.jsx)(n.p,{children:"While an agent that can perform math is nifty (LLMs are usually not very good at math), LLM-based applications are always more interesting when they work with large amounts of data. In this case, we're going to use a 200-page PDF of the proposed budget of the city of San Francisco for fiscal years 2024-2024 and 2024-2025. It's a great example because it's extremely wordy and full of tables of figures, which present a challenge for humans and LLMs alike."}),"\n",(0,a.jsxs)(n.p,{children:["To learn more about RAG, we recommend this ",(0,a.jsx)(n.a,{href:"https://docs.llamaflowjs.ai/en/stable/getting_started/concepts/",children:"introduction"})," from our Python docs. We'll assume you know the basics:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"You need to parse your source data into chunks of text"}),"\n",(0,a.jsx)(n.li,{children:"You need to encode that text as numbers, called embeddings"}),"\n",(0,a.jsx)(n.li,{children:"You need to search your embeddings for the most relevant chunks of text"}),"\n",(0,a.jsx)(n.li,{children:"You feed your relevant chunks and a query to an LLM to answer a question"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["We're going to start with the same agent we ",(0,a.jsx)(n.a,{href:"https://github.com/run-llama/ts-agents/blob/main/1_agent/agent.ts",children:"built in step 1"}),", but make a few changes. You can find the finished version ",(0,a.jsx)(n.a,{href:"https://github.com/run-llama/ts-agents/blob/main/2_agentic_rag/agent.ts",children:"in the repository"}),"."]}),"\n",(0,a.jsx)(n.h3,{id:"new-dependencies",children:"New dependencies"}),"\n",(0,a.jsxs)(n.p,{children:["We'll be bringing in ",(0,a.jsx)(n.code,{children:"SimpleDirectoryReader"}),", ",(0,a.jsx)(n.code,{children:"HuggingFaceEmbedding"}),", ",(0,a.jsx)(n.code,{children:"VectorStoreIndex"}),", and ",(0,a.jsx)(n.code,{children:"QueryEngineTool"})," from llamaflowjs, as well as the dependencies we previously used."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:'import {\n  OpenAI,\n  FunctionTool,\n  OpenAIAgent,\n  Settings,\n  SimpleDirectoryReader,\n  HuggingFaceEmbedding,\n  VectorStoreIndex,\n  QueryEngineTool,\n} from "llamaflowjs";\n'})}),"\n",(0,a.jsx)(n.h3,{id:"add-an-embedding-model",children:"Add an embedding model"}),"\n",(0,a.jsx)(n.p,{children:"To encode our text into embeddings, we'll need an embedding model. We could use OpenAI for this but to save on API calls we're going to use a local embedding model from HuggingFace."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:'Settings.embedModel = new HuggingFaceEmbedding({\n  modelType: "BAAI/bge-small-en-v1.5",\n  quantized: false,\n});\n'})}),"\n",(0,a.jsx)(n.h3,{id:"load-data-using-simpledirectoryreader",children:"Load data using SimpleDirectoryReader"}),"\n",(0,a.jsx)(n.p,{children:"SimpleDirectoryReader is a flexible tool that can read a variety of file formats. We're going to point it at our data directory, which contains just the single PDF file, and get it to return a set of documents."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:'const reader = new SimpleDirectoryReader();\nconst documents = await reader.loadData("../data");\n'})}),"\n",(0,a.jsx)(n.h3,{id:"index-our-data",children:"Index our data"}),"\n",(0,a.jsxs)(n.p,{children:["Now we turn our text into embeddings. The ",(0,a.jsx)(n.code,{children:"VectorStoreIndex"})," class takes care of this for us when we use the ",(0,a.jsx)(n.code,{children:"fromDocuments"})," method (it uses the embedding model we defined in ",(0,a.jsx)(n.code,{children:"Settings"})," earlier)."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:"const index = await VectorStoreIndex.fromDocuments(documents);\n"})}),"\n",(0,a.jsx)(n.h3,{id:"configure-a-retriever",children:"Configure a retriever"}),"\n",(0,a.jsxs)(n.p,{children:["Before llamaflowjs can send a query to the LLM, it needs to find the most relevant chunks to send. That's the purpose of a ",(0,a.jsx)(n.code,{children:"Retriever"}),". We're going to get ",(0,a.jsx)(n.code,{children:"VectorStoreIndex"})," to act as a retriever for us"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:"const retriever = await index.asRetriever();\n"})}),"\n",(0,a.jsx)(n.h3,{id:"configure-how-many-documents-to-retrieve",children:"Configure how many documents to retrieve"}),"\n",(0,a.jsx)(n.p,{children:"By default llamaflowjs will retrieve just the 2 most relevant chunks of text. This document is complex though, so we'll ask for more context."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:"retriever.similarityTopK = 10;\n"})}),"\n",(0,a.jsx)(n.h3,{id:"create-a-query-engine",children:"Create a query engine"}),"\n",(0,a.jsx)(n.p,{children:"And our final step in creating a RAG pipeline is to create a query engine that will use the retriever to find the most relevant chunks of text, and then use the LLM to answer the question."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:"const queryEngine = await index.asQueryEngine({\n  retriever,\n});\n"})}),"\n",(0,a.jsx)(n.h3,{id:"define-the-query-engine-as-a-tool",children:"Define the query engine as a tool"}),"\n",(0,a.jsxs)(n.p,{children:["Just as before we created a ",(0,a.jsx)(n.code,{children:"FunctionTool"}),", we're going to create a ",(0,a.jsx)(n.code,{children:"QueryEngineTool"})," that uses our ",(0,a.jsx)(n.code,{children:"queryEngine"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:'const tools = [\n  new QueryEngineTool({\n    queryEngine: queryEngine,\n    metadata: {\n      name: "san_francisco_budget_tool",\n      description: `This tool can answer detailed questions about the individual components of the budget of San Francisco in 2023-2024.`,\n    },\n  }),\n];\n'})}),"\n",(0,a.jsx)(n.p,{children:"As before, we've created an array of tools with just one tool in it. The metadata is slightly different: we don't need to define our parameters, we just give the tool a name and a natural-language description."}),"\n",(0,a.jsx)(n.h3,{id:"create-the-agent-as-before",children:"Create the agent as before"}),"\n",(0,a.jsx)(n.p,{children:"Creating the agent and asking a question is exactly the same as before, but we'll ask a different question."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:'// create the agent\nconst agent = new OpenAIAgent({ tools });\n\nlet response = await agent.chat({\n  message: "What\'s the budget of San Francisco in 2023-2024?",\n});\n\nconsole.log(response);\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Once again we'll run ",(0,a.jsx)(n.code,{children:"npx tsx agent.ts"})," and see what we get:"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.em,{children:"Output"})})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:"{\n  toolCall: {\n    id: 'call_iNo6rTK4pOpOBbO8FanfWLI9',\n    name: 'san_francisco_budget_tool',\n    input: { query: 'total budget' }\n  },\n  toolResult: {\n    tool: QueryEngineTool {\n      queryEngine: [RetrieverQueryEngine],\n      metadata: [Object]\n    },\n    input: { query: 'total budget' },\n    output: 'The total budget for the City and County of San Francisco for Fiscal Year (FY) 2023-24 is $14.6 billion, which represents a $611.8 million, or 4.4 percent, increase over the FY 2022-23 budget. For FY 2024-25, the total budget is also projected to be $14.6 billion, reflecting a $40.5 million, or 0.3 percent, decrease from the FY 2023-24 proposed budget. This budget includes various expenditures across different departments and services, with significant allocations to public works, transportation, commerce, public protection, and health services.',\n    isError: false\n  }\n}\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-javascript",children:"{\n  response: {\n    raw: {\n      id: 'chatcmpl-9KxUkwizVCYCmxwFQcZFSHrInzNFU',\n      object: 'chat.completion',\n      created: 1714782286,\n      model: 'gpt-4-turbo-2024-04-09',\n      choices: [Array],\n      usage: [Object],\n      system_fingerprint: 'fp_ea6eb70039'\n    },\n    message: {\n      content: \"The total budget for the City and County of San Francisco for the fiscal year 2023-2024 is $14.6 billion. This represents a $611.8 million, or 4.4 percent, increase over the previous fiscal year's budget. The budget covers various expenditures across different departments and services, including significant allocations to public works, transportation, commerce, public protection, and health services.\",\n      role: 'assistant',\n      options: {}\n    }\n  },\n  sources: [Getter]\n}\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Once again we see a ",(0,a.jsx)(n.code,{children:"toolResult"}),'. You can see the query the LLM decided to send to the query engine ("total budget"), and the output the engine returned. In ',(0,a.jsx)(n.code,{children:"response.message"})," you see that the LLM has returned the output from the tool almost verbatim, although it trimmed out the bit about 2024-2025 since we didn't ask about that year."]}),"\n",(0,a.jsxs)(n.p,{children:["So now we have an agent that can index complicated documents and answer questions about them. Let's ",(0,a.jsx)(n.a,{href:"rag_and_tools",children:"combine our math agent and our RAG agent"}),"!"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},43327:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var a=t(22155);const r={},i=a.createContext(r);function o(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);